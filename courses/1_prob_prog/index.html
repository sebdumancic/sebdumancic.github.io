<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Probabilistic Programming Seminar 2023-2024 | Sebastijan Dumancic</title> <meta name="author" content="Sebastijan Dumancic"> <meta name="description" content="Research seminar on Probabilistic programming in the TU Delft's CS Master programme"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://sebdumancic.github.io/courses/1_prob_prog/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Sebastijan </span>Dumancic</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/team/">team</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Probabilistic Programming Seminar 2023-2024</h1> <p class="post-description">Research seminar on Probabilistic programming in the TU Delft's CS Master programme</p> </header> <article> <h2 id="description">Description</h2> <p>Probabilistic programming languages (PPLs) use the syntax and semantics of programming languages to define probabilistic models. Using computer programs as a representation of probabilistic models yields two benefits. First, any computable process can be modelled as a probabilistic program. Second, PPLs enable a diverse audience – data scientists, systems designers, medical doctors, etc. – to design and reason about probabilistic systems. PPLs are becoming one of the central topics in probabilistic reasoning and programming languages, with increasing interest from industry and academia.</p> <p>This course will:</p> <ol> <li>introduce the core ideas of probabilistic programming – probabilistic inference, language design, and applications – as well as state-of-the-art ideas in the field that make PPLs more reliable, usable, and faster.</li> <li>teach you how to critically analyse state-of-the-art ideas, their strengths and weaknesses, and propose improvements.</li> </ol> <p>At the end of the course, you will be able to:</p> <ul> <li>read and write probabilistic programs</li> <li>understand how probabilistic programming languages are implemented and how they can be extended</li> <li>understand the basic and state-of-the-art probabilistic inference procedures (which are applicable beyond probabilistic programs)</li> </ul> <h2 id="prerequisites">Prerequisites</h2> <p>The target audience for this course are Master’s and PhD students. The are no formal prerequisites, but the students are expected to be comfortable with programming and mathematical notation. Basic familiarity with probability theory, artificial intelligence and machine learning is expected (equivalent to a Bachelor’s level course). We will not revise these topics during the lectures, but refresher materials are listed below.</p> <h2 id="course-format">Course Format</h2> <p>The course consists of several learning activities, alongside lectures by the intrstructor, with the points distributed as follows:</p> <ul> <li>0%: Paper reviews</li> <li>25%: Presentation</li> <li>65%: Research report</li> <li>10%: Participation</li> </ul> <p>### Course deliverables</p> <p><strong>Paper reviews.</strong> The course will take the format of a research seminar. This means that there will be no textbook and blackboard lectures; instead, we will be reading and discussing state of the art papers in the field. Consequently, you are expected to come prepared for the class by reading one of the papers covered in the lecture. As a preparation for the class, you have to write a review of that paper. The reviews consist of a few questions that help you understand the paper to sufficient extend; they will point out important points, what you should pay attention to, and which part you can avoid. Scientific articles are not always easy to read as they are typically written for people that already know a lot about the field; the review questions help you navigate that. The reviews are not graded, but are essential preparation for the classes. After the lectures, you will receive prototypical answers that help you to track your progress. These questions are in the Miro boards associated with the paper, and you should submit them in Brightspace.</p> <p><strong>Paper presentation.</strong> Only the classes in the first two weeks will be typical lectures; the goal of these lectures is to set all of you at the same starting point. Starting in week 3, you will take the lead role.</p> <p>In every lecture, we will cover 2 papers on arelated topic. Each paper will be presented by a student taking the course. You choose which paper you present. for every lecture, you are expect to read only one paper out of the 2 we cover; you will learn about the other one from the presentation of your classmate.</p> <p>For the paper you are responsible, you will understand the paper in details, including searching for additional literature that helps you to understand the paper and why it works, and present it to your colleagues. You are allowed to use any material from the Web for your presentations.</p> <p>Your objective for the presentation: explain the core idea behind the assigned paper in clearest terms possible. Don’t try to cover everything in the paper, identify important and essential parts. Convey the intuitions before the math.</p> <p>Lastly, schedule a meeting with me at least 2 days before your presentation for the feedback.</p> <p><strong>Research report.</strong> The largest part of your grade and efforts goes to a research report. In contrast to standard courses, the goal of this course is not for you to just soak up what you have been thought; instead, the goal is to go beyond the materials and think about strengths and weaknesses, and how to overcome them.</p> <p>You main task in the report is to design a research proposal, without execuyting it. You will have to dig deeper into your topic, studying papers that we will not cover in the class. The report should consist of 5 parts:</p> <ol> <li> <strong>Description of the topic</strong>. Briefly describe your topic and contextualise it within the probabilistic programming field. Describe what the problem is and why is it challenging.</li> <li> <strong>Literature study</strong>. Starting from a paper you have been assigned to, you should find several related papers (which either propose alternative solutions to the same problem, or use similar techniques for other problems). You should briefly summarise them and outline their strengths and weaknesses compared to the main paper you started with.</li> <li> <strong>Relation to other topics in the course.</strong> You cannot pass the course by only investing time into your own topic. In the report, you have to describe how it connects to every other topic we have covered (does topic X solve the same problem as your topic? Does X employ different assumptions? Does it use different techniques? …).</li> <li> <strong>Experimental test</strong>. Each paper we cover either comes with code implementing it or is easy to implement on top of existing probabilistic programming languages. You are expected to play with your method and stress-test it. You can, for example, design probabilistic programs that test the complexity of problems the inference procedures can handle, you can change parts of the techniques to see if they improve their performance or make it worse, etc. If you are re-implementing papers, you <strong>don’t</strong> have to implement them fully. Start from a simplified versions, explain your motivation for the simplification, and add complexities later on (given the time restraints).</li> <li> <strong>Research proposal(s).</strong> Describe one or more research projects you think would advance the field, focusing on your topic. The proposal should <ul> <li>Clearly describe the problem you are addressing.</li> <li>How would you address it technically, and why does that approach make sense</li> <li>How would you experimentally test it</li> <li>what could go wring with your plan. Note that I do understand that, for many of you, this is the first time encouring open-ended research project. I do not expect you to design entirely new projects no one has taught of before. While you shoudl certainty try to do that, research papers often contain ‘Future work’ sections; you are allowed to start from these suggestions and work them out in details.</li> </ul> </li> </ol> <p>Starting in week 5, you will have some time avaialble to request my feedback on your drafts. I will reserve a certain amount of time per week to read your drafts. Each of you will also get a fix amount of time, which you can divide as you wish (e.g., all at once, or distribute it through the weeks). The details will be known once I know how many people will be taking this course.</p> <p><strong>Class participation.</strong> As this is a seminar course, you are expected to <em>actively participate</em> in class. During the lectures, we will be clarifying the details from the papers, analysing their strengths, weaknesses, and evaluation; in other words, exactly what you are supposed to do in your reports. Your participation will be graded in two ways:</p> <ul> <li>Sending questions in advance. To start up discussion, I ask you to think about the papers in advance and post questions you have about it. What is a good question? Anything that helps you to understand the paper and is not of the form “What is X?” where X is something explained in the paper. Put these question in the Miro board and don’t forget to put your name next to the question.</li> <li>Helping others. Our shared goal is to understand the papers, and the field of probabilistic programming itself, together. We will maintain a shared PDF in which you can post and answer questions about papers. Answer the question in the Miro board and, again, dont’ forget to put your name.</li> </ul> <p>See <a href="#how-to-do-well-in-a-seminar-course">how to do well in a seminar course.</a></p> <h2 id="schedule">Schedule</h2> <p>You do not have to read every paper from the required literature. You will be divided in groups (group split is on Brightspace) and each group reads only one paper for the class. You will learn about the other paper from the presentation of your colleagues.</p> <p>Use review questions to focus on the important parts. Of course, you are not discouraged to go into depths of every paper.</p> <style scoped="">table{font-size:11px}</style> <font size="11"> <table> <colgroup> <col width="30%"> <col width="70%"> </colgroup> <thead> <tr class="header" style="border-bottom:1px solid black"> <th>Date</th> <th>Topic</th> </tr> </thead> <tbody> <tr valign="top"> <td> September 4, 2023 <br> (W1 L1) </td> <td> <strong>What is probabilistic programming?</strong> <br> What is model-based reasoning? The anatomy of a probabilistic program. Course structure. <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/Lecture1.pdf">[Slides]</a> </td> </tr> <tr valign="top"> <td></td> <td> Chapters 3 and 4 (without 4.4) from <a href="https://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf" rel="external nofollow noopener" target="_blank">Automating Inference, Learning, and Design using Probabilistic Programming</a> <br> Tom Rainforth<br> <br> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> September 7, 2023 <br> (W1 L2) </td> <td> <strong>Generative thinking.</strong> <br> How to write probabilistic programs? What is the distribution probabilistic program captures? <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/Lecture2.pdf">[Slides]</a> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> September 11, 2023 <br> (W2 L1) </td> <td> <strong>Basic inference procedures:</strong> <br> Enumeration, Rejection sampling, Importance Sampling, Metropolis-Hastings MCMC, Sequential Monte Carlo (Particle filtering). Why do they work? <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/Lecture3.pdf">[Slides]</a> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://probmods.org/chapters/inference-algorithms.html" rel="external nofollow noopener" target="_blank">Chapter 8</a> from <a href="https://probmods.org/index.html" rel="external nofollow noopener" target="_blank">Probabilistic models of cognition</a> <br> Noah D. Goodman, Joshua B. Tenenbaum<br> <br> <strong>Paper 2</strong> <br> Sections 4.1-4.3 from <a href="https://arxiv.org/pdf/1809.10756.pdf" rel="external nofollow noopener" target="_blank">An introduction to probabilistic programming</a> <br> Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, Frank Wood<br> <br> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> September 14, 2023 <br> (W2 L2) </td> <td> <strong>Implementation strategies.</strong> <br> Database view. Continuations. Message passing. </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="http://proceedings.mlr.press/v15/wingate11a/wingate11a.pdf" rel="external nofollow noopener" target="_blank">Lightweight Implementations of Probabilistic Programming Languages Via Transformational Compilation</a> <br> David Wingate, Andreas Stuhlmüller, Noah D. Goodman<br> <a href="https://miro.com/app/board/uXjVMtjPqNo=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/pdf/1509.02151.pdf" rel="external nofollow noopener" target="_blank">C3: Lightweight Incrementalized MCMC for Probabilistic Programs using Continuations and Callsite Caching</a> <br> Daniel Ritchie, Andreas Stuhlmuller, Noah D. Goodman<br> <a href="https://miro.com/app/board/uXjVMtiBzTw=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <strong>Paper 3</strong> <br> Sections 6.1, 6.4-6.7 from <a href="https://arxiv.org/pdf/1809.10756.pdf" rel="external nofollow noopener" target="_blank">An introduction to probabilistic programming</a> <br> Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, Frank Wood<br><br> <a href="https://miro.com/app/board/uXjVMtUZayc=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> September 18, 2023 <br> (W3 L1) </td> <td> <strong>Gradient-directed probabilistic inference</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://arxiv.org/pdf/1206.1901.pdf" rel="external nofollow noopener" target="_blank">MCMC using Hamiltonian dynamics</a> (first 20 pages) <br> Radford M. Neal<br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W3L1A.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMtiBw3s=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://docs.juliahub.com/Gen/OEZG1/0.4.1/ref/mcmc/#Built-in-Stationary-Kernels-1" rel="external nofollow noopener" target="_blank">HMC implementation in Gen.jl</a> or implement it from scratch </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/pdf/1301.1299.pdf" rel="external nofollow noopener" target="_blank">Automated Variational Inference in Probabilistic Programming</a> <br> David Wingate, Theo Weber<br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W3L1B.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMtiBw8c=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://docs.juliahub.com/Gen/OEZG1/0.4.1/ref/vi/" rel="external nofollow noopener" target="_blank">Implementation in Gen.jl</a> or <a href="https://pyro.ai/" rel="external nofollow noopener" target="_blank">Pyro</a>, or implemented a macro in Gen.jl to transform an arbitrary program into a variational one </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> September 21, 2023 <br> (W3 L2) </td> <td> <strong>Learning for inference</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://arxiv.org/pdf/1610.05735.pdf" rel="external nofollow noopener" target="_blank">Deep Amortized Inference for Probabilistic Programs</a> <br> Daniel Ritchie, Paul Horsfall, Noah D. Goodman<br> <a href="https://miro.com/app/board/uXjVMtiBw7M=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> start from Gen.jl and implement a machine learning part </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/pdf/1610.09900.pdf" rel="external nofollow noopener" target="_blank">Inference Compilation and Universal Probabilistic Programming</a> <br> Tuan Anh Le, Atılım Güneş Baydin, Frank Wood<br> <a href="https://miro.com/app/board/uXjVMthiiP4=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> implement a piple over Gen.jl or start from <a href="https://github.com/facebookresearch/lightweight-inference-compilation" rel="external nofollow noopener" target="_blank">this code</a> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> September 24 2023 <br> (W4 L1) </td> <td> <strong>Programs with stochastic support</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://arxiv.org/pdf/1910.13324.pdf" rel="external nofollow noopener" target="_blank">Divide, Conquer, and Combine: a New Inference Strategy for Probabilistic Programs with Stochastic Support</a> <br> Yuan Zhou, Hongseok Yang, Yee Whye Teh, Tom Rainforth <br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W4L1A.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMthiiLI=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://www.gen.dev/" rel="external nofollow noopener" target="_blank">Gen.jl</a> provides you with everything you need to implement a simplified version of this. You are allowed to collaborate wiht the colleague from the same session </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://openreview.net/pdf?id=wjClgX-muzB" rel="external nofollow noopener" target="_blank">Rethinking Variational Inference for Probabilistic Programs with Stochastic Support</a> <br> Tim Reichelt, Luke Ong, Tom Rainforth<br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W4L1B.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMthiid8=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://www.gen.dev/" rel="external nofollow noopener" target="_blank">Gen.jl</a> provides you with everything you need to implement a simplified version of this. You are allowed to collaborate wiht the colleague from the same session </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> September 28 2023 <br> (W4 L2) </td> <td> <strong>Programmable inference</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://dl.acm.org/doi/pdf/10.1145/3314221.3314642" rel="external nofollow noopener" target="_blank">Gen: A General-Purpose Probabilistic Programming System with Programmable Inference</a><br> Marco F. Cusumano-Towner, Feras A. Saad, Alexander K. Lew, Vikash K. Mansinghka<br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W4L2A.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMthijg8=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://www.gen.dev/" rel="external nofollow noopener" target="_blank">Gen.jl</a> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://proceedings.mlr.press/v206/lew23a.html" rel="external nofollow noopener" target="_blank">SMCP3: Sequential Monte Carlo with probabilistic program proposals</a><br> Alexander K Lew, George Matheos, Tan Zhi-Xuan, Matin Ghavamizadeh, Nishad Gothoskar, Stuart Russell, Vikash K Mansinghka<br> <a href="https://miro.com/app/board/uXjVMthiju8=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> *Code starter: <a href="https://github.com/probcomp/GenSMCP3.jl" rel="external nofollow noopener" target="_blank">Gen.jl library</a> implementing the functionality in Gen.jl, or build a simplified version from scratch </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 2, 2023 <br> (W5 L1) </td> <td> <strong>Connection between probabilistic and logical reasoning</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://www.sciencedirect.com/science/article/pii/S0004370207001889" rel="external nofollow noopener" target="_blank">On probabilistic inference by weighted model counting</a><br> Mark Chavira, Adnan Darwiche<br> <a href="https://miro.com/app/board/uXjVMthijqI=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> you can play with BDD and SDD (a better version of BDDs) though the Python library <a href="https://github.com/wannesm/PySDD" rel="external nofollow noopener" target="_blank">PySDD</a> or Julia collection of computation circuits in <a href="https://github.com/Juice-jl" rel="external nofollow noopener" target="_blank">Juice.jl</a>; there is also a BDD library in <a href="https://github.com/RenatoGeh/BDD.jl" rel="external nofollow noopener" target="_blank">Julia</a>; Problog also offers a connection to BDDs/SDDs </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/abs/2005.09089" rel="external nofollow noopener" target="_blank">Scaling Exact Inference for Discrete Probabilistic Programs</a><br> Steven Holtzen, Guy van den Broeck, Todd Millsten<br> <a href="https://miro.com/app/board/uXjVMthij2Q=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="http://dicelang.cs.ucla.edu/" rel="external nofollow noopener" target="_blank">Dice repository</a> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 5, 2023 <br> (W5 L2) </td> <td> <strong>Probabilistic logic programming</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://dtai.cs.kuleuven.be/publications/files/42447.pdf" rel="external nofollow noopener" target="_blank">ProbLog: A Probabilistic Prolog and its Application in Link Discovery</a><br> Luc De Raedt, Angelika Kimmig, Hannu Toivonen<br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W5L2A.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMtGYRCQ=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://dtai.cs.kuleuven.be/problog/" rel="external nofollow noopener" target="_blank">Problog website</a> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="k-Optimal:%20A%20novel%20approximate%20inference%20algorithm%20for%20Problog">k-Optimal: A novel approximate inference algorithm for Problog</a><br> Joris Renkens, Guy Van den Broeck, Siegfried Nijssen<br> <a href="https://miro.com/app/board/uXjVMtGYRN8=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 9, 2023 <br> (W6 L1) </td> <td> <strong>Deep probabilistic programming</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://arxiv.org/pdf/1805.10872.pdf" rel="external nofollow noopener" target="_blank">DeepProbLog: Neural Probabilistic Logic Programming</a><br> Robin Manhaeve, Sebastijan Dumančić, Angelika Kimmig, Thomas Demeester, Luc De Raedt<br> [Miro board] </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/abs/2106.12574" rel="external nofollow noopener" target="_blank">DeepStochLog: Neural Stochastic Logic Programming</a><br> Thomas Winters, Giuseppe Marra, Robin Manhaeve, Luc De Raedt<br> [Miro board] </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 12, 2023 <br> (W6 L2) </td> <td> <strong>Incremental and anytime inference</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://dl.acm.org/doi/pdf/10.1145/3296979.3192399" rel="external nofollow noopener" target="_blank">Incremental inference for probabilistic programs</a><br> Marco Cusumano-Towner, Benjamin Bichsel, Timon Gehr, Martin Vechev, Vikash K. Mansinghka<br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W6L1A.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMtGYRJE=/" rel="external nofollow noopener" target="_blank">[Miro board]</a><br> <em>Code starter:</em> <a href="https://www.gen.dev/docs/stable/ref/trace_translators/" rel="external nofollow noopener" target="_blank">Gen implementation</a> of trace translators </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://www.ijcai.org/Proceedings/15/Papers/263.pdf" rel="external nofollow noopener" target="_blank">Anytime Inference in Probabilistic Logic Programs with TP-Compilation</a><br> Jonas Vlasselaer, Guy Van den Broeck, Angelika Kimmig, Wannes Meert, Luc De Raedt<br> <a href="https://miro.com/app/board/uXjVMtGYRSI=/" rel="external nofollow noopener" target="_blank">[Miro board]</a><br> <em>Code starter:</em> anytime inference is in Problog: <a href="https://problog.readthedocs.io/en/latest/api.html#problog-forward-forward-compilation-and-evaluation" rel="external nofollow noopener" target="_blank">link</a> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 16, 2023 <br> (W7 L1) </td> <td> <strong>Deep generative models</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://arxiv.org/pdf/1505.05770.pdf" rel="external nofollow noopener" target="_blank">Variational Inference with Normalizing Flows</a><br> Danilo Jimenez Rezende, Shakir Mohamed<br> <a href="https://miro.com/app/board/uXjVMtGYRdo=/" rel="external nofollow noopener" target="_blank">[Miro board]</a><br> <em>Code starter:</em> any implementation of normalising flows like <a href="https://github.com/VincentStimper/normalizing-flows" rel="external nofollow noopener" target="_blank">normalizing flows in Pytorch</a>, <a href="https://flowtorch.ai/" rel="external nofollow noopener" target="_blank">FlowTorch</a>, or <a href="https://pyro.ai/examples/normalizing_flows_i.html" rel="external nofollow noopener" target="_blank">Pyro</a> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/abs/2006.11239" rel="external nofollow noopener" target="_blank">Denoising Diffusion Probabilistic Models</a><br> Jonathan Ho, Ajay Jain, Pieter Abbeel<br> <a href="https://miro.com/app/board/uXjVMtVcDos=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> any implementation such as <a href="https://github.com/lucidrains/denoising-diffusion-pytorch" rel="external nofollow noopener" target="_blank">this one</a> </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 19, 2023 <br> (W7 L2) </td> <td> <strong>Generalised paradigms for probabilistic programming</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://www.sciencedirect.com/science/article/pii/S157086831630088X" rel="external nofollow noopener" target="_blank">Algebraic Model Counting</a><br> Angelika Kimmig, Guy Van den Broeck, Luc De Raedt<br> <a href="https://sebdumancic.github.io/assets/teaching/probprog/2023_2024/W7L2.pdf">[Slides]</a> <a href="https://miro.com/app/board/uXjVMtFCwcM=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> Problog allows you to <a href="https://dtai.cs.kuleuven.be/problog/wasp2017/session5.html" rel="external nofollow noopener" target="_blank">play with various semirings</a> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/abs/2007.09871" rel="external nofollow noopener" target="_blank">Automating Involutive MCMC using Probabilistic and Differentiable Programming</a><br> Marco Cusumano-Towner, Alexander K. Lew, Vikash K. Mansinghka<br> <a href="https://miro.com/app/board/uXjVMtPZaUs=/" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://www.gen.dev/docs/stable/ref/mcmc/#Involutive-MCMC-1" rel="external nofollow noopener" target="_blank">Gen.jl’s implementation</a> of Involutive MCMC </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 23, 2023 <br> (W8 L1) </td> <td> <strong>No probability? No problem! Alternative sources of probabilities.</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://pubmed.ncbi.nlm.nih.gov/19205079/" rel="external nofollow noopener" target="_blank">Approximate Bayesian computation scheme for parameter inference and model selection in dynamical systems</a><br> Tina Toni, David Welch, Natalja Strelkowa, Andreas Ipsen and Michael P.H Stumpf<br> <a href="https://miro.com/app/board/uXjVMtPZad0=/?share_link_id=159807287985" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> <a href="https://www.mackelab.org/sbi/" rel="external nofollow noopener" target="_blank">SBI library</a> or implement it from scratch in <a href="https://www.gen.dev/" rel="external nofollow noopener" target="_blank">Gen.jl</a> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/pdf/1807.07706.pdf" rel="external nofollow noopener" target="_blank">Efficient Probabilistic Inference in the Quest for Physics Beyond the Standard Model</a><br> Atılım Günes Baydin et al<br> <a href="https://miro.com/app/board/uXjVMtPZabs=/?share_link_id=841848106028" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> take a much simpler simulators and work with it </td> </tr> <tr><td><br></td></tr> <tr valign="top"> <td> October 26, 2023 <br> (W8 L1) </td> <td> <strong>Learning probabilistic programs</strong> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 1</strong> <br> <a href="https://schasins.com/assets/papers/dataDrivenSynthesisOfFullProbabilisticPrograms.pdf" rel="external nofollow noopener" target="_blank">Data-Driven Synthesis of Full Probabilistic Programs</a><br> Sarah Chasins, Phitchaya Mangpo Phothilimthana<br> <a href="https://miro.com/app/board/uXjVMtPZbnk=/?share_link_id=5429881514%C2%A7" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> I recommend a fresh implementation in Gen.jl, but <a href="https://github.com/schasins/PPL-synthesis" rel="external nofollow noopener" target="_blank">the original code repository</a> might have useful information </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 2</strong> <br> <a href="https://arxiv.org/pdf/2005.14062.pdf" rel="external nofollow noopener" target="_blank">Inferring Signaling Pathways with Probabilistic Programming</a><br> David Merrell, Anthony Gitter<br> <a href="https://miro.com/app/board/uXjVMtV-GeE=/?share_link_id=847628046927" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> The code is provided in <a href="https://www.gen.dev/tutorials/rj/tutorial" rel="external nofollow noopener" target="_blank">this tutorial</a> </td> </tr> <tr valign="top"> <td></td> <td> <strong>Paper 3</strong> <br> <a href="https://arxiv.org/pdf/2111.00312.pdf" rel="external nofollow noopener" target="_blank">3DP3: 3D Scene Perception via Probabilistic Programming</a><br> Nishad Gothoskar, Marco Cusumano-Towner, Ben Zinberg, Matin Ghavamizadeh, Falk Pollok, Austin Garrett, Joshua B. Tenenbaum, Dan Gutfreund, Vikash K. Mansinghka<br> <a href="https://miro.com/app/board/uXjVNXNZrxc=/?share_link_id=435003912945" rel="external nofollow noopener" target="_blank">[Miro board]</a> <br> <em>Code starter:</em> The code is provided in <a href="https://www.gen.dev/tutorials/rj/tutorial" rel="external nofollow noopener" target="_blank">this tutorial</a> </td> </tr> <tr><td><br></td></tr> </tbody> </table> </font> <h2 id="other-materials">Other materials</h2> <h3 id="additional-materials">Additional materials</h3> <p>The course does not have a required textbook, it instead relies on selected papers. Some materials that might help you better understand probabilistic programming:</p> <ul> <li> <a href="https://probmods.org/index.html" rel="external nofollow noopener" target="_blank">Probabilistic Models of Cognition</a>: the book uses probabilistic programs to formulate models of human cognition. The book is a great introduction to using probabilistic programming and contains plenty of example to practice your modelling skills.</li> <li> <a href="http://dippl.org/" rel="external nofollow noopener" target="_blank">The Design and Implementation of Probabilistic Programming Languages</a>: a high-level book covering the basic inference procedures.</li> <li> <a href="https://arxiv.org/pdf/1809.10756.pdf" rel="external nofollow noopener" target="_blank">An Introduction to Probabilistic Programming</a>: a work-in-progress introductory textbook. Covers many topics of the course. Very good introduction to basic inference procedures, implementation strategies, and variational inference.</li> <li> <a href="https://www.morganclaypool.com/doi/10.2200/S00692ED1V01Y201601AIM032" rel="external nofollow noopener" target="_blank">Statistical Relational Artificial Intelligence: Logic, Probability, and Computation</a>: a high-level introduction to various paradigms of probabilistic logic programming.</li> <li> <a href="http://mcs.unife.it/~friguzzi/plp-book.html" rel="external nofollow noopener" target="_blank">Foundations of Probabilistic Logic Programming</a>: a deeper introduction to probabilistic logic programming.</li> <li> <a href="https://www.cis.upenn.edu/~bcpierce/tapl/" rel="external nofollow noopener" target="_blank">Types and programming languages</a>: good introduction to foundations of programming languages.</li> <li> <a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" rel="external nofollow noopener" target="_blank">Probabilistic Programming and Bayesian Methods for Hackers</a>: an easy to follow book, great at explaining key ideas intuitively.</li> </ul> <h3 id="additional-topics">Additional topics</h3> <p>Probabilistic programming is rapidly developing field. There are many topics we will not be able to cover in the class. Here is a snapshot of such topics, if you want to know more:</p> <ul> <li>Other inference tasks: The inference task we look at was the characterisation of the posterior distribution. What if we are interested in other tasks, e.g., maximising the posterior? <ul> <li><a href="https://proceedings.neurips.cc/paper/2016/file/31fefc0e570cb3860f2a6d4b38c6490d-Paper.pdf" rel="external nofollow noopener" target="_blank">Bayesian Optimization for Probabilistic Programs</a></li> <li><a href="https://arxiv.org/pdf/2106.04953.pdf" rel="external nofollow noopener" target="_blank">Expectation Programming: Adapting Probabilistic Programming Systems to Estimate Expectations Efficiently</a></li> </ul> </li> <li>Learning probabilsitic programs: a standard PP pipeline focuses on inference; but what if we don’t know the program? <ul> <li><a href="https://www.science.org/doi/epdf/10.1126/science.aab3050" rel="external nofollow noopener" target="_blank">Human-level concept learning through probabilistic program induction</a></li> <li><a href="https://arxiv.org/pdf/1907.06249.pdf" rel="external nofollow noopener" target="_blank">Bayesian Synthesis of Probabilistic Programs for Automatic Data Modeling</a></li> <li><a href="https://arxiv.org/pdf/1703.05698.pdf" rel="external nofollow noopener" target="_blank">Neural Sketch Learning for Conditional Program Generation</a></li> </ul> </li> <li>Semantics of probabilistic programming languages: how to define the meaning of a probabilistic program? <ul> <li><a href="https://www.cambridge.org/core/books/foundations-of-probabilistic-programming/semantics-of-probabilistic-programming-a-gentle-introduction/A7964205E44B5234A78C661192E294E1" rel="external nofollow noopener" target="_blank">Semantics of Probabilistic Programming: A Gentle Introduction</a></li> <li><a href="https://arxiv.org/pdf/1601.04943.pdf" rel="external nofollow noopener" target="_blank">Semantics for probabilistic programming: higher-order functions, continuous distributions, and soft constraints</a></li> <li><a href="https://www.cs.cornell.edu/~kozen/Papers/ProbSem.pdf" rel="external nofollow noopener" target="_blank">Semantics of Probabilistic programs</a></li> </ul> </li> <li>Deep generative models: an alternative framework for generative modelling based on neural networks. It has less flexibility than PPL but better learning properties. <ul> <li><a href="https://link.springer.com/book/10.1007/978-3-030-93158-2" rel="external nofollow noopener" target="_blank">Deep Generative Modelling</a></li> </ul> </li> <li>Analysis of probabilistic programs: <ul> <li><a href="https://arxiv.org/pdf/2010.11887.pdf" rel="external nofollow noopener" target="_blank">Conditional independence by typing</a></li> <li><a href="https://dl.acm.org/doi/pdf/10.1145/2676726.2677001" rel="external nofollow noopener" target="_blank">Probabilistic Termination: Soundness, Completeness, and Compositionality</a></li> </ul> </li> <li>Nested probabilistic programs: probabilistic programs that call probabilistic programs <ul> <li><a href="https://arxiv.org/pdf/1803.06328.pdf" rel="external nofollow noopener" target="_blank">Nesting probabilistic programs</a></li> <li><a href="https://www.sciencedirect.com/science/article/pii/S1389041713000387" rel="external nofollow noopener" target="_blank">Reasoning about reasoning by nested conditioning: Modeling theory of mind with probabilistic programs</a></li> <li><a href="https://arxiv.org/pdf/1612.00951.pdf" rel="external nofollow noopener" target="_blank">On the Pitfalls of Nested Monte Carlo</a></li> </ul> </li> <li>Stochastic conditioning: in the course, the observations always came in form of the exact value of a variable. What if we want to condition on a distribution? <ul> <li><a href="https://arxiv.org/pdf/2010.00282.pdf" rel="external nofollow noopener" target="_blank">Probabilistic Programs with Stochastic Conditioning</a></li> </ul> </li> <li>Deep probabilistic programming: we have touched upon various interaction between probabilistic programming and deep neural networks. Deep probabilistic programming is a paradigm that combines the two, often with murky boundaries from e.g. variational or amortised inference. <ul> <li><a href="https://www.sciencedirect.com/science/article/pii/S0004370221000552" rel="external nofollow noopener" target="_blank">Neural probabilistic logic programming</a></li> <li><a href="https://arxiv.org/abs/1701.03757?context=cs.PL" rel="external nofollow noopener" target="_blank">Deep Probabilistic Programming</a></li> </ul> </li> </ul> <h3 id="courses-at-other-universities">Courses at other universities</h3> <ul> <li> <a href="https://www.cs.ubc.ca/~fwood/CS532W-539W/" rel="external nofollow noopener" target="_blank">Probabilistic programming</a> by Frank Wood at University of British Columbia, Canada</li> <li> <a href="https://www.khoury.northeastern.edu/home/sholtzen/CS7480Fall21/" rel="external nofollow noopener" target="_blank">seminar course</a> by Steven Holtzen at Northeastern, USA</li> <li> <a href="https://docs.google.com/document/d/1MJXs0OdUS9sVL3LjTfEFK6i-Jz06cAKG21N_auE85wM/pub" rel="external nofollow noopener" target="_blank">seminar course</a> by Dan Roy at University of Toronto, Canada, which focuses on theoretical aspects of probabilistic programming</li> <li> <a href="https://github.com/aleatory-science/deep-probprog-course" rel="external nofollow noopener" target="_blank">Deep Probabilistic Programming course</a> by Thomas Hamelryck and Ahmad Salim Al-Sibahi at University of Copenhagen, Denmark</li> <li> <a href="https://www.cs.tufts.edu/comp/150PP/" rel="external nofollow noopener" target="_blank">Probabilistic Programming Languages course</a> by Norman Ramsey at Tufts University, USA</li> <li> <a href="http://web.cs.ucla.edu/~guyvdb/teaching/cs267a/2022s/" rel="external nofollow noopener" target="_blank">Probabilistic Programming and Relational Learning</a> bu Guy Van den Broeck at UCLA, USA.</li> <li> <a href="https://github.com/hongseok-yang/probprog17" rel="external nofollow noopener" target="_blank">Probabilistic Programming course</a> by Hongseok Yang at KAIST, South Korea</li> </ul> <h2 id="practicalities">Practicalities</h2> <h3 id="how-to-do-well-in-a-seminar-course">How to do well in a seminar course</h3> <p>A seminar course is different from a standard course in two ways: (1) “just” learning the topics covered by the materials is not enough; and (2) you are expected to actively participate in the lectures. The active participation includes giving a presentation (see <a href="#preparing-you-presentation">Preparing your presentation</a>) and discussing the materials during the lecture. Actually, the lectures will consist only of these two activities. The exceptions are week 1, which contain two lectures by the instructor, and week 2, in which we discuss papers but no one has to prepare the presentation. Each student will present one paper and is expected to actively contribute in discussions.</p> <p>If understanding the materials is not enough, what is? In a seminar course, we teach you to think beyond what you have been served. In fact, if you only master the materials, that will get you a mere 6. Instead, you are expected to critically analyse every paper you read. For every paper you read, think about the following questions:</p> <ul> <li>What is the main idea proposed in the paper?</li> <li>Which problem does it solve?</li> <li>What are its strengths?</li> <li>What are its weaknesses?</li> <li>Which parts of the paper were/and perhaps still are confusing to you?</li> <li>Do you have an impression that the idea works just because the authors made some particular choices?</li> <li>What are the implicit assumption the authors are making?</li> <li>Do you see multiple options to solve a subproblem X and are wondering why the authors chose</li> <li>Is the idea properly evaluated? If not, what is missing? How would you do it?</li> <li>Are the arguments for the idea convincing?</li> <li>How would you extend the work?</li> </ul> <p>During the discussion part of the lectures, we will discuss these questions and compare your observation. Not all questions are applicable to every paper, so don’t worry if you cannot relate some of them to some papers. The quality of the discussion will therefore depend on you. Importantly, you have to come prepared for each lecture.</p> <p>It is important that you actively participate in the discussion. As a rule of thumb, the more you talk, the higher your grade will be in the end. However, <em>be constructive</em> and avoid saying something just to say something. I don’t want you to be quiet the entire quarter, but that does not mean that you have to say something in every discussion. Sometimes you would have something brief to say, sometimes you would have some deeper insight. That is fine. As a rule of thumb, I expect you to say something at least every few lectures. Don’t be upset if I respond to you or even correct you. For most of you, this is the first time you are participating in a seminar. It is expected that you need some guidance. Moreover, I tend to jump in when you mention something interesting without (perhaps) realising it.</p> <p>An important difference between a regular course and a seminar is that you will not be penalised for not understanding something. That does not mean that this is a free-pass course, but rather that it is ok to build up towards an understnading during the course. You will be reading research papers, often in depth.<br> In contrast to textbooks, research papers are concise and expect certain knowledge from a reader. This has two consequence. First, it is likely that you will not know some of the necessary concepts and would have to fill the gap to understand the paper. You should go through that process. Second, scientists are often not great writers – they might explain simple concepts very confusingly because they have different audience in mind (peers, not students). For any of these reasons, you might not understand a part of the paper. This is normal and you should not hide it – confusing parts of the paper are great starters for discussions!</p> <p>Here are a few situations that are acceptable in a seminar course, but perhaps not in a regular course:</p> <ol> <li>You misunderstand something in a paper and provide a wrong answer in a review. If you realise that during the lecture, you can correct you answer after the lecture. That is fine.</li> <li>You misunderstand something that leads you to an interesting idea for an extension. This is perfectly fine if your reasoning taking the misunderstanding as a fact is correct and interesting.</li> <li>You just can’t understand what the paper is trying to say. Voice it in the lecture! Try to phrase it as a detailed question; point out as specifically as possible where you lost it</li> </ol> <h3 id="preparing-your-presentation">Preparing your presentation</h3> <p>You will have to present one paper to the group. Student presentation start in week 3.</p> <p>Your presentation should take 15 mins. This is an estimate, some papers might require less while other more time. If you think you have to go beyond this limit, discuss it with me.</p> <p>Approach your presentation as a short lecture. You goal is to explain the topic to your colleagues so that they learn from the lecture; only half of the student in the class will have read the paper. Think about the right way to explain the topic; this might not be the way it was explained in the paper. For instance, if you found that you had to look a lot of other concepts, explain them before the topic you are covering. Use illustrations and animations, you can find lots of them online (if not for the exact topic, then for something very related that could help you explain the intuition). Provide a working example, especially if such an example is not present in the original paper.</p> <p>Feel free to use “non-academic” materials for your preparations: blogs, videos, informal notes… I don’t care what you use as long as you understand the topic. Importantly, if you encounter materials that you found more useful than the one I proposed, share them with me.</p> <p>Your main focus in the presentation should be to convey the idea/concept to your colleagues. This usually means that you have to think about not only how to convey the idea effectively but also which parts of the paper to include or skip. There will be no correlation between the amount of content squeezed in a lecture and a grade. Often it makes sense to skip something to optimise for clarity.</p> <p><strong>Important:</strong> schedule a meeting with me at least 2 days before your presentation; this is to ensure that your presentation is of sufficient quality to provide a valuable learning experience to your colleagues.</p> <h3 id="project---implementation">Project - implementation</h3> <h3 id="project---report">Project - report</h3> <h3 id="course-feedback">Course feedback</h3> <p>This is the first edition of the course. As you can imagine, this is kind of a beta version of the course. To make sure the course offers the best learning experience to you, I would appreciate if you provide feedback throughout the course. What works for you? What doesn’t? Do you have an idea how to improve something?</p> <p>You can submit the feedback anonymously <a href="https://forms.gle/PUGRCUwsZp4HNGbC7" rel="external nofollow noopener" target="_blank">HERE</a>.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Sebastijan Dumancic. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>